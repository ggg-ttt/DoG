# AgentVerseå¤šæ™ºèƒ½ä½“è¾©è®ºæœºåˆ¶è¯¦è§£

## ğŸ“š AgentVerse æ–‡ä»¶å¤¹ç»“æ„

æ ¹æ®é¡¹ç›®å®é™…ç»“æ„ï¼Œ`agentverse`æ–‡ä»¶å¤¹çš„æ ¸å¿ƒç»„ç»‡å¦‚ä¸‹ï¼š

```
agentverse/
â”œâ”€â”€ __init__.py              # æ¨¡å—å…¥å£ï¼Œæš´éœ²æ ¸å¿ƒæ¥å£
â”œâ”€â”€ agents/                  # æ™ºèƒ½ä½“å®šä¹‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py              # æ™ºèƒ½ä½“åŸºç±»
â”‚   â”œâ”€â”€ agent.py             # é€šç”¨æ™ºèƒ½ä½“å®ç°
â”‚   â””â”€â”€ llm.py               # LLMè°ƒç”¨å°è£…
â”œâ”€â”€ environments/            # è¾©è®ºç¯å¢ƒ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py              # ç¯å¢ƒåŸºç±»
â”‚   â””â”€â”€ rules/               # è¾©è®ºè§„åˆ™
â”‚       â”œâ”€â”€ base.py
â”‚       â”œâ”€â”€ order/           # å‘è¨€é¡ºåºè§„åˆ™
â”‚       â””â”€â”€ visibility/      # æ¶ˆæ¯å¯è§æ€§è§„åˆ™
â”œâ”€â”€ message.py               # æ¶ˆæ¯å®šä¹‰
â”œâ”€â”€ initialization.py        # ç³»ç»Ÿåˆå§‹åŒ–
â”œâ”€â”€ simulation.py            # æ¨¡æ‹Ÿè¿è¡Œå™¨
â””â”€â”€ tasks/                   # ä»»åŠ¡é…ç½®
    â””â”€â”€ kgqa/
        â”œâ”€â”€ freebase/
        â”‚   â””â”€â”€ three_role_one_turn_sequential_freebase/
        â”‚       â””â”€â”€ config.yaml
        â””â”€â”€ metaqa/
            â””â”€â”€ three_role_one_turn_sequential_metaqa/
                â””â”€â”€ config.yaml
```

---

## ğŸ”‘ æ ¸å¿ƒå®ç°æœºåˆ¶

### ä¸€ã€æ¨¡å—å…¥å£ (`__init__.py`)

è¿™æ˜¯æ•´ä¸ªæ¡†æ¶çš„å…¥å£ç‚¹ï¼Œè´Ÿè´£æš´éœ²æ ¸å¿ƒç±»å’Œå‡½æ•°ã€‚

```python
# filepath: agentverse/__init__.py (æ ¸å¿ƒé€»è¾‘)

from agentverse.agents import Agent
from agentverse.environments import Environment  
from agentverse.simulation import Simulation
from agentverse.initialization import load_agent, load_environment

# æä¾›ä¾¿æ·çš„ä»»åŠ¡åŠ è½½å‡½æ•°
def load_task(task_name: str):
    """
    åŠ è½½æŒ‡å®šä»»åŠ¡çš„é…ç½®
    
    å‚æ•°:
        task_name: ä»»åŠ¡è·¯å¾„ï¼Œå¦‚ "kgqa/freebase/three_role_one_turn_sequential_freebase"
    
    è¿”å›:
        é…ç½®å¥½çš„Simulationå¯¹è±¡
    """
    config_path = f"agentverse/tasks/{task_name}/config.yaml"
    return Simulation.from_config(config_path)
```

**ä½¿ç”¨æ–¹å¼ï¼š**
```python
from agentverse import load_task

# åŠ è½½KGQAè¾©è®ºä»»åŠ¡
simulation = load_task("kgqa/freebase/three_role_one_turn_sequential_freebase")
result = simulation.run(question="Who directed Inception?")
```

---

### äºŒã€æ™ºèƒ½ä½“æ¨¡å— (`agents/`)

#### 2.1 æ™ºèƒ½ä½“åŸºç±» (`agents/base.py`)

å®šä¹‰æ‰€æœ‰æ™ºèƒ½ä½“çš„é€šç”¨æ¥å£å’ŒåŸºæœ¬è¡Œä¸ºã€‚

```python
# filepath: agentverse/agents/base.py (æ ¸å¿ƒé€»è¾‘)

from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
from agentverse.message import Message

class BaseAgent(ABC):
    """æ™ºèƒ½ä½“æŠ½è±¡åŸºç±»"""
    
    def __init__(
        self,
        name: str,
        role_description: str,
        memory: Optional[List[Message]] = None,
        **kwargs
    ):
        self.name = name
        self.role_description = role_description
        self.memory = memory or []
        
    @abstractmethod
    async def astep(self, env_description: str) -> Message:
        """
        å¼‚æ­¥æ‰§è¡Œä¸€æ­¥æ¨ç†
        
        å‚æ•°:
            env_description: å½“å‰ç¯å¢ƒæè¿°ï¼ˆåŒ…å«å…¶ä»–æ™ºèƒ½ä½“çš„å‘è¨€ï¼‰
        
        è¿”å›:
            æ™ºèƒ½ä½“ç”Ÿæˆçš„æ¶ˆæ¯
        """
        pass
    
    def step(self, env_description: str) -> Message:
        """åŒæ­¥æ‰§è¡Œä¸€æ­¥æ¨ç†"""
        import asyncio
        return asyncio.run(self.astep(env_description))
    
    def add_message_to_memory(self, message: Message):
        """å°†æ¶ˆæ¯æ·»åŠ åˆ°è®°å¿†"""
        self.memory.append(message)
    
    def reset(self):
        """é‡ç½®æ™ºèƒ½ä½“çŠ¶æ€"""
        self.memory = []
```

#### 2.2 LLMæ™ºèƒ½ä½“ (`agents/agent.py`)

å®ç°åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä½“ã€‚

```python
# filepath: agentverse/agents/agent.py (æ ¸å¿ƒé€»è¾‘)

from agentverse.agents.base import BaseAgent
from agentverse.message import Message
from agentverse.llm import LLMClient

class Agent(BaseAgent):
    """åŸºäºLLMçš„æ™ºèƒ½ä½“å®ç°"""
    
    def __init__(
        self,
        name: str,
        role_description: str,
        system_prompt: str,
        model_name: str = "gpt-4",
        temperature: float = 0.7,
        max_tokens: int = 2000,
        **kwargs
    ):
        super().__init__(name, role_description, **kwargs)
        self.system_prompt = system_prompt
        self.llm = LLMClient(
            model=model_name,
            temperature=temperature,
            max_tokens=max_tokens
        )
    
    async def astep(self, env_description: str) -> Message:
        """
        æ‰§è¡Œä¸€æ­¥æ¨ç†
        
        æµç¨‹:
        1. æ„å»ºå®Œæ•´æç¤ºè¯
        2. è°ƒç”¨LLMç”Ÿæˆå›å¤
        3. è§£æå¹¶è¿”å›æ¶ˆæ¯
        """
        # 1. æ„å»ºæç¤ºè¯
        prompt = self._build_prompt(env_description)
        
        # 2. è°ƒç”¨LLM
        response = await self.llm.agenerate(prompt)
        
        # 3. åˆ›å»ºæ¶ˆæ¯
        message = Message(
            sender=self.name,
            content=response,
            turn=-1  # å°†ç”±ç¯å¢ƒè®¾ç½®
        )
        
        # 4. ä¿å­˜åˆ°è®°å¿†
        self.add_message_to_memory(message)
        
        return message
    
    def _build_prompt(self, env_description: str) -> str:
        """
        æ„å»ºæç¤ºè¯
        
        ç»“æ„:
        - ç³»ç»Ÿæç¤ºï¼ˆè§’è‰²å®šä¹‰ï¼‰
        - å†å²å¯¹è¯
        - å½“å‰ç¯å¢ƒæè¿°
        """
        prompt_parts = []
        
        # ç³»ç»Ÿæç¤º
        prompt_parts.append(f"[System]\n{self.system_prompt}\n")
        
        # è§’è‰²æè¿°
        prompt_parts.append(f"[Your Role]\n{self.role_description}\n")
        
        # å†å²è®°å¿†
        if self.memory:
            prompt_parts.append("[Previous Discussion]")
            for msg in self.memory[-10:]:  # ä¿ç•™æœ€è¿‘10æ¡
                prompt_parts.append(f"{msg.sender}: {msg.content}")
        
        # å½“å‰ç¯å¢ƒ
        prompt_parts.append(f"\n[Current Situation]\n{env_description}")
        
        # è¯·æ±‚å›å¤
        prompt_parts.append(f"\n[Your Response as {self.name}]:")
        
        return "\n".join(prompt_parts)
```

#### 2.3 LLMå®¢æˆ·ç«¯ (`agents/llm.py`)

å°è£…å¤§è¯­è¨€æ¨¡å‹çš„è°ƒç”¨ã€‚

```python
# filepath: agentverse/agents/llm.py (æ ¸å¿ƒé€»è¾‘)

import os
import openai
from typing import List, Dict

class LLMClient:
    """LLMè°ƒç”¨å®¢æˆ·ç«¯"""
    
    def __init__(
        self,
        model: str = "gpt-4",
        temperature: float = 0.7,
        max_tokens: int = 2000
    ):
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens
        
        # é…ç½®API
        openai.api_key = os.environ.get("OPENAI_API_KEY")
        if os.environ.get("OPENAI_API_BASE"):
            openai.api_base = os.environ.get("OPENAI_API_BASE")
    
    async def agenerate(self, prompt: str) -> str:
        """å¼‚æ­¥ç”Ÿæˆå›å¤"""
        try:
            response = await openai.ChatCompletion.acreate(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=self.temperature,
                max_tokens=self.max_tokens
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"LLMè°ƒç”¨é”™è¯¯: {e}")
            return ""
    
    def generate(self, prompt: str) -> str:
        """åŒæ­¥ç”Ÿæˆå›å¤"""
        import asyncio
        return asyncio.run(self.agenerate(prompt))
```

---

### ä¸‰ã€æ¶ˆæ¯æ¨¡å— (`message.py`)

å®šä¹‰æ™ºèƒ½ä½“é—´é€šä¿¡çš„æ¶ˆæ¯æ ¼å¼ã€‚

```python
# filepath: agentverse/message.py (æ ¸å¿ƒé€»è¾‘)

from dataclasses import dataclass, field
from typing import Optional, Dict, Any, List

@dataclass
class Message:
    """æ™ºèƒ½ä½“æ¶ˆæ¯"""
    
    sender: str                          # å‘é€è€…åç§°
    content: str                         # æ¶ˆæ¯å†…å®¹
    receiver: Optional[str] = None       # æ¥æ”¶è€…ï¼ˆNone=å¹¿æ’­ï¼‰
    turn: int = -1                       # è¾©è®ºè½®æ¬¡
    msg_type: str = "text"               # æ¶ˆæ¯ç±»å‹
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def __str__(self):
        return f"[{self.sender}] (Turn {self.turn}): {self.content[:100]}..."
    
    def to_dict(self) -> Dict:
        return {
            "sender": self.sender,
            "content": self.content,
            "receiver": self.receiver,
            "turn": self.turn,
            "msg_type": self.msg_type,
            "metadata": self.metadata
        }


@dataclass  
class MessagePool:
    """æ¶ˆæ¯æ±  - ç®¡ç†æ‰€æœ‰è¾©è®ºæ¶ˆæ¯"""
    
    messages: List[Message] = field(default_factory=list)
    
    def add(self, message: Message):
        """æ·»åŠ æ¶ˆæ¯"""
        self.messages.append(message)
    
    def get_visible_messages(
        self, 
        agent_name: str,
        visibility_rule: str = "all"
    ) -> List[Message]:
        """
        è·å–å¯¹ç‰¹å®šæ™ºèƒ½ä½“å¯è§çš„æ¶ˆæ¯
        
        å¯è§æ€§è§„åˆ™:
        - "all": æ‰€æœ‰æ¶ˆæ¯å¯è§
        - "previous": åªèƒ½çœ‹åˆ°è‡ªå·±å‘è¨€å‰çš„æ¶ˆæ¯
        - "none": çœ‹ä¸åˆ°å…¶ä»–äººçš„æ¶ˆæ¯
        """
        if visibility_rule == "all":
            return self.messages.copy()
        elif visibility_rule == "previous":
            # æ‰¾åˆ°è¯¥æ™ºèƒ½ä½“æœ€åä¸€æ¡æ¶ˆæ¯çš„ä½ç½®
            visible = []
            for msg in self.messages:
                if msg.sender == agent_name:
                    break
                visible.append(msg)
            return visible
        else:
            return []
    
    def get_by_turn(self, turn: int) -> List[Message]:
        """è·å–æŒ‡å®šè½®æ¬¡çš„æ¶ˆæ¯"""
        return [m for m in self.messages if m.turn == turn]
    
    def get_last_n(self, n: int) -> List[Message]:
        """è·å–æœ€è¿‘næ¡æ¶ˆæ¯"""
        return self.messages[-n:] if n < len(self.messages) else self.messages
```

---

### å››ã€ç¯å¢ƒæ¨¡å— (`environments/`)

#### 4.1 ç¯å¢ƒåŸºç±» (`environments/base.py`)

```python
# filepath: agentverse/environments/base.py (æ ¸å¿ƒé€»è¾‘)

from abc import ABC, abstractmethod
from typing import List, Dict, Any
from agentverse.agents import BaseAgent
from agentverse.message import Message, MessagePool

class BaseEnvironment(ABC):
    """è¾©è®ºç¯å¢ƒåŸºç±»"""
    
    def __init__(
        self,
        agents: List[BaseAgent],
        max_turns: int = 3,
        **kwargs
    ):
        self.agents = agents
        self.max_turns = max_turns
        self.message_pool = MessagePool()
        self.current_turn = 0
    
    @abstractmethod
    async def astep(self) -> List[Message]:
        """å¼‚æ­¥æ‰§è¡Œä¸€è½®è¾©è®º"""
        pass
    
    @abstractmethod
    def get_env_description(self, agent: BaseAgent) -> str:
        """è·å–å¯¹ç‰¹å®šæ™ºèƒ½ä½“çš„ç¯å¢ƒæè¿°"""
        pass
    
    def reset(self):
        """é‡ç½®ç¯å¢ƒ"""
        self.message_pool = MessagePool()
        self.current_turn = 0
        for agent in self.agents:
            agent.reset()
```

#### 4.2 é¡ºåºè¾©è®ºç¯å¢ƒ

è¿™æ˜¯DoGé¡¹ç›®ä½¿ç”¨çš„æ ¸å¿ƒç¯å¢ƒï¼Œå®ç°"ä¸‰è§’è‰²å•è½®é¡ºåºè¾©è®º"ã€‚

```python
# filepath: agentverse/environments/sequential_debate.py (æ ¸å¿ƒé€»è¾‘)

from typing import List
from agentverse.environments.base import BaseEnvironment
from agentverse.agents import BaseAgent
from agentverse.message import Message

class SequentialDebateEnvironment(BaseEnvironment):
    """
    é¡ºåºè¾©è®ºç¯å¢ƒ
    
    ç‰¹ç‚¹:
    - æ™ºèƒ½ä½“æŒ‰å›ºå®šé¡ºåºå‘è¨€
    - æ¯ä¸ªæ™ºèƒ½ä½“å¯ä»¥çœ‹åˆ°ä¹‹å‰æ‰€æœ‰å‘è¨€
    - æ”¯æŒå¤šè½®è¾©è®ºç›´åˆ°è¾¾æˆå…±è¯†
    """
    
    def __init__(
        self,
        agents: List[BaseAgent],
        max_turns: int = 3,
        speaking_order: List[str] = None,
        **kwargs
    ):
        super().__init__(agents, max_turns, **kwargs)
        
        # è®¾ç½®å‘è¨€é¡ºåº
        if speaking_order:
            self.speaking_order = speaking_order
        else:
            self.speaking_order = [agent.name for agent in agents]
    
    async def astep(self) -> List[Message]:
        """
        æ‰§è¡Œä¸€è½®è¾©è®º
        
        æµç¨‹:
        1. æŒ‰é¡ºåºè®©æ¯ä¸ªæ™ºèƒ½ä½“å‘è¨€
        2. æ¯ä¸ªæ™ºèƒ½ä½“å¯ä»¥çœ‹åˆ°ä¹‹å‰çš„æ‰€æœ‰å‘è¨€
        3. æ”¶é›†æœ¬è½®æ‰€æœ‰æ¶ˆæ¯
        """
        turn_messages = []
        
        for agent_name in self.speaking_order:
            # æ‰¾åˆ°å¯¹åº”çš„æ™ºèƒ½ä½“
            agent = self._get_agent_by_name(agent_name)
            if agent is None:
                continue
            
            # æ„å»ºç¯å¢ƒæè¿°
            env_desc = self.get_env_description(agent)
            
            # è·å–æ™ºèƒ½ä½“å›å¤
            message = await agent.astep(env_desc)
            message.turn = self.current_turn
            
            # æ·»åŠ åˆ°æ¶ˆæ¯æ± 
            self.message_pool.add(message)
            turn_messages.append(message)
        
        self.current_turn += 1
        return turn_messages
    
    def get_env_description(self, agent: BaseAgent) -> str:
        """
        æ„å»ºç¯å¢ƒæè¿°
        
        åŒ…å«:
        - å½“å‰é—®é¢˜
        - ä¹‹å‰æ‰€æœ‰æ™ºèƒ½ä½“çš„å‘è¨€
        - å¯¹å½“å‰æ™ºèƒ½ä½“çš„æœŸæœ›
        """
        desc_parts = []
        
        # æ·»åŠ ä¹‹å‰çš„å‘è¨€
        visible_messages = self.message_pool.get_visible_messages(
            agent.name, 
            visibility_rule="all"
        )
        
        if visible_messages:
            desc_parts.append("Previous discussion:")
            for msg in visible_messages:
                desc_parts.append(f"  [{msg.sender}]: {msg.content}")
        
        return "\n".join(desc_parts)
    
    def _get_agent_by_name(self, name: str) -> BaseAgent:
        """æ ¹æ®åç§°è·å–æ™ºèƒ½ä½“"""
        for agent in self.agents:
            if agent.name == name:
                return agent
        return None
```

---

### äº”ã€æ¨¡æ‹Ÿè¿è¡Œå™¨ (`simulation.py`)

åè°ƒæ•´ä¸ªè¾©è®ºæµç¨‹çš„æ‰§è¡Œã€‚

```python
# filepath: agentverse/simulation.py (æ ¸å¿ƒé€»è¾‘)

import yaml
from typing import Dict, Any, List
from agentverse.agents import Agent
from agentverse.environments import SequentialDebateEnvironment
from agentverse.message import Message

class Simulation:
    """è¾©è®ºæ¨¡æ‹Ÿå™¨"""
    
    def __init__(
        self,
        agents: List[Agent],
        environment: SequentialDebateEnvironment,
        max_turns: int = 3
    ):
        self.agents = agents
        self.environment = environment
        self.max_turns = max_turns
    
    @classmethod
    def from_config(cls, config_path: str) -> "Simulation":
        """ä»é…ç½®æ–‡ä»¶åˆ›å»ºæ¨¡æ‹Ÿå™¨"""
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # åˆ›å»ºæ™ºèƒ½ä½“
        agents = []
        for agent_config in config['agents']:
            agent = Agent(
                name=agent_config['name'],
                role_description=agent_config['role_description'],
                system_prompt=agent_config.get('system_prompt', ''),
                model_name=agent_config.get('model', 'gpt-4'),
                temperature=agent_config.get('temperature', 0.7)
            )
            agents.append(agent)
        
        # åˆ›å»ºç¯å¢ƒ
        env_config = config.get('environment', {})
        environment = SequentialDebateEnvironment(
            agents=agents,
            max_turns=env_config.get('max_turns', 3),
            speaking_order=env_config.get('speaking_order')
        )
        
        return cls(
            agents=agents,
            environment=environment,
            max_turns=env_config.get('max_turns', 3)
        )
    
    def run(self, question: str) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„è¾©è®ºæµç¨‹
        
        å‚æ•°:
            question: éœ€è¦è¾©è®ºçš„é—®é¢˜
            
        è¿”å›:
            åŒ…å«æœ€ç»ˆç­”æ¡ˆå’Œè¾©è®ºå†å²çš„å­—å…¸
        """
        import asyncio
        return asyncio.run(self.arun(question))
    
    async def arun(self, question: str) -> Dict[str, Any]:
        """å¼‚æ­¥è¿è¡Œè¾©è®º"""
        
        # 1. é‡ç½®ç¯å¢ƒ
        self.environment.reset()
        
        # 2. æ·»åŠ åˆå§‹é—®é¢˜åˆ°æ¶ˆæ¯æ± 
        initial_message = Message(
            sender="System",
            content=f"Question to debate: {question}",
            turn=0
        )
        self.environment.message_pool.add(initial_message)
        
        # 3. æ‰§è¡Œå¤šè½®è¾©è®º
        all_messages = []
        for turn in range(self.max_turns):
            turn_messages = await self.environment.astep()
            all_messages.extend(turn_messages)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾æˆå…±è¯†
            if self._check_consensus(turn_messages):
                break
        
        # 4. æå–æœ€ç»ˆç­”æ¡ˆ
        final_answer = self._extract_final_answer()
        
        return {
            'question': question,
            'answer': final_answer,
            'total_turns': self.environment.current_turn,
            'debate_history': [msg.to_dict() for msg in all_messages]
        }
    
    def _check_consensus(self, messages: List[Message]) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦è¾¾æˆå…±è¯†
        
        ç®€å•ç­–ç•¥ï¼šæ£€æŸ¥Summarizeræ˜¯å¦ç»™å‡ºäº†æ˜ç¡®ç­”æ¡ˆ
        """
        for msg in messages:
            if "Summarizer" in msg.sender:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜ç¡®çš„ç­”æ¡ˆæ ‡è®°
                if "Final Answer:" in msg.content or "æœ€ç»ˆç­”æ¡ˆ:" in msg.content:
                    return True
        return False
    
    def _extract_final_answer(self) -> str:
        """ä»è¾©è®ºå†å²ä¸­æå–æœ€ç»ˆç­”æ¡ˆ"""
        messages = self.environment.message_pool.messages
        
        # ä»åå¾€å‰æ‰¾Summarizerçš„å‘è¨€
        for msg in reversed(messages):
            if "Summarizer" in msg.sender:
                return msg.content
        
        # å¦‚æœæ²¡æœ‰Summarizerï¼Œè¿”å›æœ€åä¸€æ¡æ¶ˆæ¯
        if messages:
            return messages[-1].content
        
        return "No answer generated"
```

---

### å…­ã€ä»»åŠ¡é…ç½® (YAMLé…ç½®æ–‡ä»¶)

#### 6.1 Freebaseä»»åŠ¡é…ç½®

```yaml
# filepath: agentverse/tasks/kgqa/freebase/three_role_one_turn_sequential_freebase/config.yaml

task_name: "KGQA_Freebase_ThreeRole"
description: "Three-role debate for KGQA on Freebase"

# æ™ºèƒ½ä½“é…ç½®
agents:
  - name: "Proposer"
    role_description: |
      You are the Answer Proposer in a knowledge graph QA debate.
      Your job is to:
      1. Analyze the given question carefully
      2. Identify relevant entities and relations
      3. Propose candidate answers with reasoning
      
      Always explain your reasoning process step by step.
    system_prompt: |
      You are participating in a multi-agent debate to answer questions 
      using a knowledge graph. Be analytical and thorough.
    model: "gpt-4"
    temperature: 0.7

  - name: "Critic"  
    role_description: |
      You are the Critical Reviewer in a knowledge graph QA debate.
      Your job is to:
      1. Carefully examine the proposed answers
      2. Identify potential issues, errors, or missing information
      3. Challenge weak reasoning and ask clarifying questions
      
      Be constructive but rigorous in your criticism.
    system_prompt: |
      You are a critical thinker. Question assumptions and 
      look for logical flaws.
    model: "gpt-4"
    temperature: 0.8

  - name: "Summarizer"
    role_description: |
      You are the Decision Maker in a knowledge graph QA debate.
      Your job is to:
      1. Consider all arguments from Proposer and Critic
      2. Weigh the evidence and reasoning
      3. Provide the final answer with confidence level
      
      Format your final answer as:
      Final Answer: [your answer]
      Confidence: [high/medium/low]
      Reasoning: [brief explanation]
    system_prompt: |
      You are a fair judge. Synthesize different viewpoints and 
      make balanced decisions.
    model: "gpt-4"
    temperature: 0.6

# ç¯å¢ƒé…ç½®
environment:
  type: "SequentialDebate"
  max_turns: 1                    # DoGä½¿ç”¨å•è½®è¾©è®º
  speaking_order:
    - "Proposer"
    - "Critic"
    - "Summarizer"
  message_visibility: "all"       # æ‰€æœ‰æ¶ˆæ¯å¯¹æ‰€æœ‰æ™ºèƒ½ä½“å¯è§

# è¾“å‡ºé…ç½®
output:
  save_debate_history: true
  format: "json"
```

#### 6.2 MetaQAä»»åŠ¡é…ç½®

```yaml
# filepath: agentverse/tasks/kgqa/metaqa/three_role_one_turn_sequential_metaqa/config.yaml

task_name: "KGQA_MetaQA_ThreeRole"
description: "Three-role debate for KGQA on MetaQA"

agents:
  - name: "Proposer"
    role_description: |
      You are analyzing questions about movies, actors, directors, etc.
      Use your knowledge to propose answers based on the MetaQA knowledge base.
      
      For multi-hop questions, break them down into steps:
      - 1-hop: Direct relation query
      - 2-hop: Two-step relation traversal
      - 3-hop: Three-step relation traversal
    system_prompt: "You are a movie knowledge expert."
    model: "gpt-4"
    temperature: 0.7

  - name: "Critic"
    role_description: |
      Review the proposed answers for movie-related questions.
      Check for:
      - Correct entity identification
      - Valid relation paths
      - Logical consistency
    system_prompt: "You are a critical reviewer of movie knowledge."
    model: "gpt-4"
    temperature: 0.8

  - name: "Summarizer"
    role_description: |
      Synthesize the debate and provide the final answer.
      Format: Final Answer: [answer]
    system_prompt: "You make final decisions based on debate."
    model: "gpt-4"
    temperature: 0.6

environment:
  type: "SequentialDebate"
  max_turns: 1
  speaking_order: ["Proposer", "Critic", "Summarizer"]
```

---

## ğŸ”„ å®Œæ•´å·¥ä½œæµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KGQA_TASK/main_*.py                      â”‚
â”‚                         è°ƒç”¨å…¥å£                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              agentverse.load_task(task_name)                â”‚
â”‚                   åŠ è½½ä»»åŠ¡é…ç½®                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Simulation.from_config()                       â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚    â”‚  1. è§£æconfig.yaml                               â”‚     â”‚
â”‚    â”‚  2. åˆ›å»ºAgentå®ä¾‹ (Proposer, Critic, Summarizer) â”‚     â”‚
â”‚    â”‚  3. åˆ›å»ºSequentialDebateEnvironment              â”‚     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  simulation.run(question)                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚    â”‚  Turn 1:                                          â”‚     â”‚
â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚
â”‚    â”‚  â”‚ Proposer.astep() â†’ æå‡ºå€™é€‰ç­”æ¡ˆ              â”‚ â”‚     â”‚
â”‚    â”‚  â”‚      â†“ (æ¶ˆæ¯æ·»åŠ åˆ°MessagePool)              â”‚ â”‚     â”‚
â”‚    â”‚  â”‚ Critic.astep()   â†’ æ‰¹è¯„å’Œè´¨ç–‘               â”‚ â”‚     â”‚
â”‚    â”‚  â”‚      â†“ (æ¶ˆæ¯æ·»åŠ åˆ°MessagePool)              â”‚ â”‚     â”‚
â”‚    â”‚  â”‚ Summarizer.astep() â†’ æ€»ç»“ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ       â”‚ â”‚     â”‚
â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚
â”‚    â”‚                                                   â”‚     â”‚
â”‚    â”‚  æ£€æŸ¥å…±è¯† â†’ å¦‚æœè¾¾æˆåˆ™ç»“æŸï¼Œå¦åˆ™ç»§ç»­ä¸‹ä¸€è½®        â”‚     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     è¿”å›ç»“æœ                                 â”‚
â”‚  {                                                          â”‚
â”‚    "question": "åŸå§‹é—®é¢˜",                                   â”‚
â”‚    "answer": "æœ€ç»ˆç­”æ¡ˆ",                                     â”‚
â”‚    "total_turns": 1,                                        â”‚
â”‚    "debate_history": [...]                                  â”‚
â”‚  }                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ ä¸‰è§’è‰²è¾©è®ºæœºåˆ¶è¯¦è§£

### è§’è‰²åˆ†å·¥

| è§’è‰² | è‹±æ–‡å | èŒè´£ | ç‰¹ç‚¹ |
|------|--------|------|------|
| æè®®è€… | Proposer | åˆ†æé—®é¢˜ï¼Œæå‡ºå€™é€‰ç­”æ¡ˆ | ç§¯æä¸»åŠ¨ï¼Œé€»è¾‘æ¸…æ™° |
| æ‰¹è¯„è€… | Critic | å®¡æŸ¥ç­”æ¡ˆï¼ŒæŒ‡å‡ºé—®é¢˜ | æ‰¹åˆ¤æ€§æ€ç»´ï¼Œä¸¥è°¨ |
| æ€»ç»“è€… | Summarizer | ç»¼åˆæ„è§ï¼Œæœ€ç»ˆå†³ç­– | å¹³è¡¡å„æ–¹ï¼Œæœæ–­ |

### è¾©è®ºæµç¨‹

```
Question: "Who directed the movie Inception?"

Round 1:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Proposer]:                                                 â”‚
â”‚ Let me analyze this question about the movie Inception.     â”‚
â”‚                                                             â”‚
â”‚ Entity identified: "Inception" (movie)                      â”‚
â”‚ Relation needed: "director"                                 â”‚
â”‚                                                             â”‚
â”‚ Candidate Answer: Christopher Nolan                         â”‚
â”‚ Reasoning: Christopher Nolan is well-known for directing    â”‚
â”‚ Inception (2010), which he also wrote.                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Critic]:                                                   â”‚
â”‚ I'll review the Proposer's answer.                          â”‚
â”‚                                                             â”‚
â”‚ Strengths:                                                  â”‚
â”‚ - Correct entity identification                             â”‚
â”‚ - Valid reasoning about Christopher Nolan                   â”‚
â”‚                                                             â”‚
â”‚ Potential Issues:                                           â”‚
â”‚ - Should verify this is the only "Inception" movie          â”‚
â”‚ - Confidence seems high, which is appropriate here          â”‚
â”‚                                                             â”‚
â”‚ Assessment: The answer appears correct and well-reasoned.   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Summarizer]:                                               â”‚
â”‚ Based on the debate:                                        â”‚
â”‚                                                             â”‚
â”‚ - Proposer identified Christopher Nolan as director         â”‚
â”‚ - Critic validated the reasoning with minor caveats         â”‚
â”‚ - Both agree on the answer                                  â”‚
â”‚                                                             â”‚
â”‚ Final Answer: Christopher Nolan                             â”‚
â”‚ Confidence: High                                            â”‚
â”‚ Reasoning: Clear consensus with valid knowledge graph path  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ å…³é”®è®¾è®¡ç‰¹ç‚¹

### 1. æ¨¡å—åŒ–è®¾è®¡
- æ™ºèƒ½ä½“ã€ç¯å¢ƒã€æ¶ˆæ¯å„è‡ªç‹¬ç«‹
- æ˜“äºæ‰©å±•å’Œæ›¿æ¢ç»„ä»¶

### 2. é…ç½®é©±åŠ¨
- é€šè¿‡YAMLé…ç½®å®šä¹‰ä»»åŠ¡
- æ— éœ€ä¿®æ”¹ä»£ç å³å¯è°ƒæ•´å‚æ•°

### 3. å¼‚æ­¥æ”¯æŒ
- æ”¯æŒå¼‚æ­¥æ‰§è¡Œæé«˜æ•ˆç‡
- å¯å¹¶è¡Œè°ƒç”¨å¤šä¸ªLLM

### 4. çµæ´»çš„æ¶ˆæ¯å¯è§æ€§
- å¯é…ç½®æ™ºèƒ½ä½“çœ‹åˆ°å“ªäº›æ¶ˆæ¯
- æ”¯æŒä¸åŒçš„è¾©è®ºç­–ç•¥

### 5. å¯æ‰©å±•çš„è§’è‰²ç³»ç»Ÿ
- æ˜“äºæ·»åŠ æ–°çš„æ™ºèƒ½ä½“è§’è‰²
- è‡ªå®šä¹‰è§’è‰²è¡Œä¸ºå’Œæç¤ºè¯

---

## ğŸ”§ å¦‚ä½•ä¿®æ”¹è¾©è®ºç­–ç•¥

### 1. æ·»åŠ æ–°è§’è‰²

åœ¨`config.yaml`ä¸­æ·»åŠ æ–°çš„æ™ºèƒ½ä½“é…ç½®ï¼š

```yaml
agents:
  # ...existing agents...
  
  - name: "Verifier"
    role_description: |
      You verify answers against the knowledge graph.
      Check if the answer can be reached through valid paths.
    model: "gpt-4"
    temperature: 0.5
```

### 2. ä¿®æ”¹å‘è¨€é¡ºåº

```yaml
environment:
  speaking_order:
    - "Proposer"
    - "Critic"
    - "Verifier"    # æ–°å¢
    - "Summarizer"
```

### 3. å¢åŠ è¾©è®ºè½®æ•°

```yaml
environment:
  max_turns: 3  # ä»1è½®æ”¹ä¸º3è½®
```

### 4. ä¿®æ”¹æ¨¡å‹å‚æ•°

```yaml
agents:
  - name: "Proposer"
    model: "gpt-4-turbo"    # ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
    temperature: 0.5        # é™ä½éšæœºæ€§
    max_tokens: 3000        # å¢åŠ è¾“å‡ºé•¿åº¦
```

---

è¿™ä»½æ–‡æ¡£å®Œæ•´è§£é‡Šäº†AgentVerseæ¡†æ¶å®ç°å¤šæ™ºèƒ½ä½“è¾©è®ºçš„æ‰€æœ‰æ ¸å¿ƒæœºåˆ¶ï¼
